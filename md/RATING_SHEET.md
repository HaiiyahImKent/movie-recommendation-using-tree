# Final Project Presentation Rating Sheet (Aligned to Provided Rubric)

Use this rubric during evaluation. The “Guidance for 10/10” under each criterion tells the team how to perform at the Outstanding level.

| Criteria                                                                                   | Score Options                                              | Remarks                                                                                                                                                                                                                                                                                                                              |
| ------------------------------------------------------------------------------------------ | ---------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| 1. Quality of Research (Comprehensive/Scholarly/Newness of Concepts and in-depth research) | 10 – Outstanding<br>6 – Satisfactory<br>3 – For the Effort | Guidance for 10/10: Show literature or credible sources on Decision Trees, DFS/BFS, ranking heuristics, and TMDB discover parameters. Cite why strict `with_genres` + `without_genres` improves purity, and compare with alternatives (e.g., OMDB limitations). Include novelty: strict-only query builders and client-side ranking. |
| 2. Professionalism in Delivery/Execution and Preparedness                                  | 10 – Outstanding<br>6 – Satisfactory<br>3 – For the Effort | Guidance for 10/10: Smart casual attire; start and end on time (≤15 mins). Roles assigned; smooth handoffs; demo rehearsed. Have contingencies (screenshots, smaller page size), and a clear closing. No filler, no technical hiccups.                                                                                               |
| 3. Engagement of participants and teamwork                                                 | 10 – Outstanding<br>6 – Satisfactory<br>3 – For the Effort | Guidance for 10/10: All members speak concisely; Demo Driver interacts with flows confidently; Tech Explainer answers at least one prepared question; Lead Presenter manages time. Use brief audience checks (e.g., “Notice thriller-only purity”).                                                                                  |
| 4. Documentation Grade                                                                     | 10 – Outstanding<br>6 – Satisfactory<br>3 – For the Effort | Guidance for 10/10: Polished documentation and Canva deck: consistent headings, readable typography, aligned visuals. Include architecture diagram, DS/Algo rationale, demo script, limitations/next steps. No spelling/grammar errors.                                                                                              |

## Evaluator Scoring (Optional Totals)

-   Criterion 1: \_\_\_/10
-   Criterion 2: \_\_\_/10
-   Criterion 3: \_\_\_/10
-   Criterion 4: \_\_\_/10

Total: \_\_\_/40

## Team Checklist for 10/10

-   Research: Cite 3–5 sources (docs/blogs/papers) on Decision Trees, genre-based discovery, and ranking; explain why TMDB over OMDB.
-   Preparedness: Rehearse twice; ensure API key and demo flows work; keep to 15 minutes.
-   Engagement: Assign roles; ensure each member has a speaking part; plan 2 quick audience prompts.
-   Documentation: Canva + MD docs consistent; include architecture, DS/Algo sections, demo steps, and conclusions.

## Evaluator Notes

-   Strengths:
-   Improvements:
-   Questions:
